{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Match_MLU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2O78/fbZ12kXSkw+5RMoY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janina712/MLTSA22_JBoecher/blob/main/Other/3.%20Match_MLU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0. Import & Set-Up**"
      ],
      "metadata": {
        "id": "y5foIPlFYxCF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oeyduNDx-Fn4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import os\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjhQ3dDP-KVJ",
        "outputId": "41c10dc1-68c1-4ebd-dccd-9db55cb24b28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline/2.BreathGroups_Assigned/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTr2gWXQ-Mob",
        "outputId": "16b9f4b9-4433-45a4-e211-b52bacb7bb61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/RhythmAnalysisPipeline/2.BreathGroups_Assigned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reading = pd.read_excel(\"reading_TextGrid_comb_BG_loop.xlsx\")\n",
        "interview = pd.read_excel(\"interview_TextGrid_comb_BG_loop.xlsx\")"
      ],
      "metadata": {
        "id": "auwA6jOU-MhK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IDs = ['24fa', '24ma', '24mb', '26f', '29ma', '29mb', '29mc', '32m', '34m', '35mb', '46ma', '50fa', '50fb', '54f', '57m', '60m', '62f', '62m','C1_DS', 'C2_JH', 'C3_MD', 'C4_ZO', 'C5_HL', 'C6_LH', 'C7_SH', 'C9_RD',  'C10_KS', 'C11_NP', 'C12_CC', 'C13_RG']"
      ],
      "metadata": {
        "id": "74SKf1v8-Q39"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subj_col = pd.DataFrame(['24fa', '24ma', '24mb', '26f', '29ma', '29mb', '29mc', '32m', '34m', '35mb', '46ma', '50fa', '50fb', '54f', '57m', '60m', '62f', '62m','C1_DS', 'C2_JH', 'C3_MD', 'C4_ZO', 'C5_HL', 'C6_LH', 'C7_SH', 'C9_RD', 'C10_KS', 'C11_NP', 'C12_CC', 'C13_RG'], columns = [\"ID\"])"
      ],
      "metadata": {
        "id": "PrO6jatX-V3U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "control_IDs = ['C1_DS', 'C2_JH', 'C3_MD', 'C4_ZO', 'C5_HL', 'C6_LH', 'C7_SH', 'C9_RD', 'C10_KS', 'C11_NP', 'C12_CC', 'C13_RG']"
      ],
      "metadata": {
        "id": "CBE0iJrx-Zii"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Functions**"
      ],
      "metadata": {
        "id": "6TyIAixsYuCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Assign Participant Group**"
      ],
      "metadata": {
        "id": "NL_9tczv-cbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_group(df):\n",
        "  group = pd.DataFrame(index = range(len(df)),columns=[\"Group\"])\n",
        "\n",
        "  for i in range(0,len(df)):\n",
        "    if \"_\" in df[\"ID\"][i]:\n",
        "      group[\"Group\"][i] = \"Control\"\n",
        "    else:\n",
        "      group[\"Group\"][i] = \"PWS\"\n",
        "  \n",
        "  df_out = pd.concat([ group, df], axis=1)\n",
        "  df_out = df_out[df_out.Type != \"silence\"]\n",
        "  df_out.index = range(len(df_out.index))\n",
        "  df_out.drop(['Unnamed: 0'], axis=1 , inplace = True)\n",
        "  return(df_out)"
      ],
      "metadata": {
        "id": "5bEE4RA0-fhj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Count Vowels**"
      ],
      "metadata": {
        "id": "BIs6iaUh-jLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_vowels(df):  \n",
        "  df_vowels = df[df[\"Type\"]  == \"vowel\"] \n",
        "  df_vowels.index = range(len(df_vowels.index))\n",
        "\n",
        "  syll_col = pd.DataFrame()  ## initialize group-level dataframe\n",
        "  for ID in IDs: ## loop over participnts\n",
        "    syll_current_ID = pd.DataFrame()   ## initialize participant-level dataframe\n",
        "    subset_sounds = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_sounds.index = range(len(subset_sounds.index)) # reset index\n",
        "    subset_vowels = subset_sounds[subset_sounds[\"Type\"] == \"vowel\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_vowels.index = range(len(subset_vowels.index)) # reset index\n",
        "    syll = subset_vowels[\"Breath.Group\"].value_counts().sort_index() # count how often a certain Breath group occurs for this participant\n",
        "    syll.index = range(len(syll.index)) # reset index\n",
        "    for a in range (0,len(syll)): # go through all breath groups that this participant produced\n",
        "      syll_current_BG = pd.DataFrame()  ## initialize BG-level dataframe\n",
        "      syll_current_BG = pd.DataFrame(np.repeat(syll.iloc[a], syll.iloc[a], axis=0)) #replicate the sum sum times\n",
        "      syll_current_ID = syll_current_ID.append([syll_current_BG], ignore_index = True) # add BG-level dataframe to participant-level dataframe \n",
        "    syll_col = syll_col.append([syll_current_ID], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "\n",
        "  df_vowels = pd.concat([df_vowels, syll_col], axis=1)\n",
        "  #df_vowels.drop(['Syllables'], axis=1 , inplace = True)\n",
        "  df_vowels.rename(columns = {'Syllables':'Unmached_Vowels'}, inplace = True)\n",
        "  df_vowels.rename(columns = {0:'Syllables'}, inplace = True) # rename new column\n",
        "  pre_df_vowel_avg = df_vowels.groupby(\"Group\").mean()    ########### average counting 13 13 times\n",
        "\n",
        "  return(df_vowels, pre_df_vowel_avg)"
      ],
      "metadata": {
        "id": "GU5KQG89-n0k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Count Consonants**"
      ],
      "metadata": {
        "id": "_fjALDDM-uKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_consonants(df):  \n",
        "  df_consonants = df[df[\"Type\"]  == \"consonant\"] \n",
        "  df_consonants.index = range(len(df_consonants.index))\n",
        "\n",
        "  con_col = pd.DataFrame()  ## initialize group-level dataframe\n",
        "  for ID in IDs: ## loop over participnts\n",
        "    con_current_ID = pd.DataFrame()   ## initialize participant-level dataframe\n",
        "    subset_sounds = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_sounds.index = range(len(subset_sounds.index)) # reset index\n",
        "    subset_cons = subset_sounds[subset_sounds[\"Type\"] == \"consonant\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_cons.index = range(len(subset_cons.index)) # reset index\n",
        "    con = subset_cons[\"Breath.Group\"].value_counts().sort_index() # count how often a certain Breath group occurs for this participant\n",
        "    con.index = range(len(con.index)) # reset index\n",
        "    for a in range (0,len(con)): # go through all breath groups that this participant produced\n",
        "      con_current_BG = pd.DataFrame()  ## initialize BG-level dataframe\n",
        "      con_current_BG = pd.DataFrame(np.repeat(con.iloc[a], con.iloc[a], axis=0)) #replicate the sum sum times\n",
        "      con_current_ID = con_current_ID.append([con_current_BG], ignore_index = True) # add BG-level dataframe to participant-level dataframe \n",
        "    con_col = con_col.append([con_current_ID], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "\n",
        "  df_consonants = pd.concat([df_consonants, con_col], axis=1)\n",
        "  #df_consonants.drop(['Consonants'], axis=1 , inplace = True)\n",
        "  df_consonants.rename(columns = {'Consonants':'Unmatched_Cons'}, inplace = True)\n",
        "  df_consonants.rename(columns = {0:'Consonants'}, inplace = True) # rename new column\n",
        "  pre_df_consonant_avg = df_consonants.groupby(\"Group\").mean()    ########### average counting 13 13 times\n",
        "\n",
        "  return(df_consonants, pre_df_consonant_avg)"
      ],
      "metadata": {
        "id": "3rHV1y7h-xio"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Average Vowel Count by Participant**"
      ],
      "metadata": {
        "id": "HNK9tHE8-7vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def participant_vowel_avg(df):  \n",
        "  group_col = pd.DataFrame(index = range(len(subj_col)),columns=[\"Group\"])\n",
        "  for i in range(0,len(group_col)):\n",
        "    if \"_\" in subj_col[\"ID\"][i]:\n",
        "      group_col[\"Group\"][i] = \"Control\"\n",
        "    else:\n",
        "      group_col[\"Group\"][i] = \"PWS\"\n",
        "  \n",
        "  n = -1\n",
        "  avg_col = pd.DataFrame(index = range(len(subj_col)),columns=[\"Syllables\"])\n",
        "  for ID in IDs: ## loop over participnts\n",
        "    n = n + 1\n",
        "    subset_BGs = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "    BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "    subj_avg = BG_avg[\"Syllables\"].mean()\n",
        "    avg_col[\"Syllables\"][n] = subj_avg\n",
        "\n",
        "  df_participant_vowel_avg = pd.concat([group_col, subj_col, avg_col], axis=1)\n",
        "\n",
        "  return(df_participant_vowel_avg)"
      ],
      "metadata": {
        "id": "ThtJbCxy_Ah0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Average Consonant Count by Participant**"
      ],
      "metadata": {
        "id": "HeiTsry4_IEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def participant_consonant_avg(df):  \n",
        "  group_col = pd.DataFrame(index = range(len(subj_col)),columns=[\"Group\"])\n",
        "  for i in range(0,len(group_col)):\n",
        "    if \"_\" in subj_col[\"ID\"][i]:\n",
        "      group_col[\"Group\"][i] = \"Control\"\n",
        "    else:\n",
        "      group_col[\"Group\"][i] = \"PWS\"\n",
        "  \n",
        "  n = -1\n",
        "  avg_col = pd.DataFrame(index = range(len(subj_col)),columns=[\"Consonants\"])\n",
        "  for ID in IDs: ## loop over participnts\n",
        "    n = n + 1\n",
        "    subset_BGs = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "    BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "    subj_avg = BG_avg[\"Consonants\"].mean()\n",
        "    avg_col[\"Consonants\"][n] = subj_avg\n",
        "\n",
        "  df_participant_cons_avg = pd.concat([group_col, subj_col, avg_col], axis=1)\n",
        "\n",
        "  return(df_participant_cons_avg)"
      ],
      "metadata": {
        "id": "0YgGSmaY_L_L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Compare Consonant and Vowel Counts Across Participant Groups (PWS vs. Control)**"
      ],
      "metadata": {
        "id": "s-TyNdAN_SA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_groups(df_vowels, df_consonants):\n",
        "  #comparison_v = df_vowels.groupby(\"Group\").mean()\n",
        "  #control_v = comparison_v[\"Syllables\"][0]\n",
        "  #pws_v = comparison_v[\"Syllables\"][1]\n",
        "  control_v = (df_vowels.groupby(\"ID\").mean()[\"Syllables\"][18:30]).mean()\n",
        "  pws_v = (df_vowels.groupby(\"ID\").mean()[\"Syllables\"][0:18]).mean()\n",
        "  difference_v = control_v - pws_v\n",
        "\n",
        "  #comparison_c = df_consonants.groupby(\"Group\").mean()\n",
        "  #control_c = comparison_c[\"Consonants\"][0]\n",
        "  #pws_c = comparison_c[\"Consonants\"][1]\n",
        "  control_c = (df_consonants.groupby(\"ID\").mean()[\"Consonants\"][18:30]).mean()\n",
        "  pws_c = (df_consonants.groupby(\"ID\").mean()[\"Consonants\"][0:18]).mean()\n",
        "  difference_c = control_c - pws_c\n",
        "\n",
        "  string1 = (f\"PWS produced on average {round(pws_v,2)} syllables per utterance, while control participants produced {round(control_v,2)} syllables on average.\")\n",
        "  string2 = (f\"This means that on average control participants produced {round(difference_v,2)} syllables more per utterance.\")\n",
        "  string3 = (f\"\\nPWS produced on average {round(pws_c,2)} consonants per utterance, while control participants produced {round(control_c,2)} consonants on average.\")\n",
        "  string4 = (f\"This means that on average control participants produced {round(difference_c,2)} consonants more per utterance.\")\n",
        "\n",
        "  return(string1, string2, string3, string4, pws_v, pws_c, difference_v, difference_c)"
      ],
      "metadata": {
        "id": "a9ZYa7rp_ZKl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Match Number of Vowels Per Utterance**"
      ],
      "metadata": {
        "id": "lYx6TnBZ_fBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match_vowels(df_vowels, pws_v, cut_v):\n",
        "  cut_v = math.ceil(cut_v) ##+ 5                                                           ################## number chosen because \"it works well\". \n",
        "  syll_col_matched = pd.DataFrame()  ## initialize group-level dataframe              ################ No real motivation. Come up with strategy! ############\n",
        "  participant = pd.DataFrame()  ## initialize participant-level dataframe\n",
        "  df_control = df_vowels[df_vowels[\"Group\"]  == \"Control\"] \n",
        "  df_control.index = range(len(df_control.index)) ## group\n",
        "  for ID in control_IDs:\n",
        "    df_control_ID = df_control[df_control[\"ID\"]  == ID] \n",
        "    df_control_ID.index = range(len(df_control_ID.index))  ### person\n",
        "    BGs = df_control_ID[\"Breath.Group\"].unique()\n",
        "    for i in range(0,len(BGs)):\n",
        "      df_control_ID_BG = df_control_ID[df_control_ID[\"Breath.Group\"]  == i] \n",
        "      df_control_ID_BG.index = range(len(df_control_ID_BG.index)) ## BG\n",
        "      if len(df_control_ID_BG) >= cut_v:\n",
        "        df_control_ID_BG.drop(df_control_ID_BG.tail(cut_v).index, inplace = True) \n",
        "        participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "      else:  \n",
        "        participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "  syll_col_matched = syll_col_matched.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "\n",
        "  return(syll_col_matched)"
      ],
      "metadata": {
        "id": "uoetWRx4_jWh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Match Number of Consonants Per Utterance**"
      ],
      "metadata": {
        "id": "gNAmLl8E_nAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match_consonants(df_consonants, pws_c, cut_c):\n",
        "  cut_c = math.ceil(cut_c) ##+ 4                                                       ################## number chosen because \"it works well\".\n",
        "  cons_col_matched = pd.DataFrame()  ## initialize group-level dataframe          ################ No real motivation. Come up with strategy! ############\n",
        "  participant = pd.DataFrame()  ## initialize participant-level dataframe\n",
        "  df_control = df_consonants[df_consonants[\"Group\"]  == \"Control\"] \n",
        "  df_control.index = range(len(df_control.index)) ## group\n",
        "  for ID in control_IDs:\n",
        "    df_control_ID = df_control[df_control[\"ID\"]  == ID] \n",
        "    df_control_ID.index = range(len(df_control_ID.index))  ### person\n",
        "    BGs = df_control_ID[\"Breath.Group\"].unique()\n",
        "    for i in range(0,len(BGs)):\n",
        "      df_control_ID_BG = df_control_ID[df_control_ID[\"Breath.Group\"]  == i] \n",
        "      df_control_ID_BG.index = range(len(df_control_ID_BG.index)) ## BG\n",
        "      if len(df_control_ID_BG) >= cut_c:\n",
        "        df_control_ID_BG.drop(df_control_ID_BG.tail(cut_c).index, inplace = True) \n",
        "        participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "      else:  \n",
        "        participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "  cons_col_matched = cons_col_matched.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "  return(cons_col_matched)"
      ],
      "metadata": {
        "id": "2dxTzRVg_q2P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Test if Remaining Vowel Difference Between Groups is Statistically Significant**"
      ],
      "metadata": {
        "id": "_jIp8xeYAyBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ttest_vowelDifference(matched_participant_df, cut_v): \n",
        "  cut_v = round(cut_v)\n",
        "  ttest_control = matched_participant_df[18:30]  \n",
        "  ttest_pws = matched_participant_df[0:18]   \n",
        "\n",
        "  control_v =  matched_participant_df[18:30].mean()[0]\n",
        "  pws_v =  matched_participant_df[0:18].mean()[0]\n",
        "\n",
        "  difference_v_matched = control_v - pws_v\n",
        "\n",
        "  df_v_matched_test = stats.ttest_ind(ttest_control['Syllables'],\n",
        "                        ttest_pws['Syllables'])\n",
        "  if df_v_matched_test[1] >= 0.05:\n",
        "    level = \"insignificant\"\n",
        "  else:\n",
        "    level = \"significant\"\n",
        "  string11 = (f\"Control utterances that were longer than the mean average length of PWS utterances were shortened. \\nAfter matching, PWS had {round(pws_v,2)} vowels per utterance, while control participants had {round(control_v,2)} per utterance. \\nThe difference is reduced to {abs(round(difference_v_matched,2))}, which is statistically {level} (p = {round(df_v_matched_test[1],2)}).\")\n",
        "\n",
        "  return(string11)"
      ],
      "metadata": {
        "id": "Qpkmbv1dA48L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Test if Remaining Consonant Difference Between Groups is Statistically Significant**"
      ],
      "metadata": {
        "id": "oB_v2Do5_-T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ttest_conDifference(matched_participant_df, cut_c):  \n",
        "  cut_c = round(cut_c)\n",
        "  ttest_control = matched_participant_df[18:30]\n",
        "  ttest_pws = matched_participant_df[0:18]  \n",
        "\n",
        "  control_c =  matched_participant_df[18:30].mean()[0]\n",
        "  pws_c =  matched_participant_df[0:18].mean()[0]\n",
        "\n",
        "  difference_c_matched = control_c - pws_c\n",
        "\n",
        "  df_c_matched_test = stats.ttest_ind(ttest_control['Consonants'],\n",
        "                        ttest_pws['Consonants'])\n",
        "  if df_c_matched_test[1] >= 0.05:\n",
        "    level = \"insignificant\"\n",
        "  else:\n",
        "    level = \"significant\"\n",
        "  string11 = (f\"Control utterances that were longer than the mean average length of PWS utterances, were shortened by {round(cut_c,2)} consonants. \\nAfter matching, PWS had {round(pws_c,2)} consonants per utterance, while control participants had {round(control_c,2)} per utterance. \\nThe difference is reduced to {abs(round(difference_c_matched,2))}, which is statistically {level} (p = {round(df_c_matched_test[1],2)}).\")\n",
        "\n",
        "  return(string11)"
      ],
      "metadata": {
        "id": "kOkbDbKdAIrv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conduct Matching Analysis using Functions**"
      ],
      "metadata": {
        "id": "IS9fvIXABWV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add new column to dataframe that denotes participant's group membership (PWS vs. Control)\n",
        "interview = assign_group(interview)\n",
        "reading = assign_group(reading)"
      ],
      "metadata": {
        "id": "5Wy0bBQKB9bJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count vowels per utterance \n",
        "# output 1: df of size \"interview\", with an additional #vowels per utterance for each row (redundant for BG)\n",
        "# output 2: df of size \"len(Group)\" (2), that contains average # vowels per breath group for PWS group vs. Control group \n",
        "[interview_vowels, pre_interview_vowel_avg]  = count_vowels(interview)\n",
        "[reading_vowels, pre_reading_vowel_avg] = count_vowels(reading)"
      ],
      "metadata": {
        "id": "WoVGC2FECtmO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count consonants per utterance \n",
        "# output 1: df of size \"interview\", with an additional #consonants per utterance for each row (redundant for BG)\n",
        "# output 2: df of size \"len(Group)\" (2), that contains average # consonants per breath group for PWS group vs. Control group \n",
        "[interview_consonants, pre_interview_consonant_avg]  = count_consonants(interview)\n",
        "[reading_consonants, pre_reading_consonants_avg] = count_consonants(reading)"
      ],
      "metadata": {
        "id": "8Qlw9EVdCva6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # vowels per breath group for each participant \n",
        "interview_participant_vowel_avg = participant_vowel_avg(interview_vowels)\n",
        "reading_participant_vowel_avg = participant_vowel_avg(reading_vowels)"
      ],
      "metadata": {
        "id": "3KtyX_nPCy8X"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # consonants per breath group for each participant \n",
        "interview_participant_cons_avg = participant_consonant_avg(interview_consonants)\n",
        "reading_participant_cons_avg = participant_consonant_avg(reading_consonants)"
      ],
      "metadata": {
        "id": "rXQnEwfrC6wn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance \n",
        "# interview\n",
        "string1, string2, string3, string4, pws_v_inter, pws_c_inter, difference_v_inter, difference_c_inter = compare_groups(interview_participant_vowel_avg, interview_participant_cons_avg)\n",
        "\n",
        "print(string1)\n",
        "print(string2)\n",
        "print(string3)\n",
        "print(string4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L2XWvlnC-8_",
        "outputId": "03eab333-89ae-4f23-d074-22d30e98ad51"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 7.87 syllables per utterance, while control participants produced 9.84 syllables on average.\n",
            "This means that on average control participants produced 1.96 syllables more per utterance.\n",
            "\n",
            "PWS produced on average 11.59 consonants per utterance, while control participants produced 15.38 consonants on average.\n",
            "This means that on average control participants produced 3.79 consonants more per utterance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance \n",
        "# reading\n",
        "string5, string6, string7, string8, pws_v_read, pws_c_read, difference_v_read, difference_c_read  = compare_groups(reading_participant_vowel_avg, reading_participant_cons_avg)\n",
        "\n",
        "print(string5)\n",
        "print(string6)\n",
        "print(string7)\n",
        "print(string8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Ace-XrICeI",
        "outputId": "af0c7fd0-5b1f-45f2-d4ca-1f605083e775"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 8.54 syllables per utterance, while control participants produced 11.76 syllables on average.\n",
            "This means that on average control participants produced 3.22 syllables more per utterance.\n",
            "\n",
            "PWS produced on average 13.13 consonants per utterance, while control participants produced 18.05 consonants on average.\n",
            "This means that on average control participants produced 4.93 consonants more per utterance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# match number of vowels per utterance by cutting long control utterances (longer than pws average) by the difference in average vowel number between groups\n",
        "matched_vowels_read = match_vowels(reading_vowels,pws_v_read, difference_v_read)\n",
        "matched_vowels_inter = match_vowels(interview_vowels, pws_v_inter, difference_v_inter)"
      ],
      "metadata": {
        "id": "rH720-ZrDDZy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# match number of consonants per utterance by cutting long control utterances (longer than pws average) by the difference in average consonant number between groups\n",
        "matched_consonants_read = match_vowels(reading_consonants,pws_c_read, difference_c_read)\n",
        "matched_consonants_inter = match_vowels(interview_consonants, pws_c_inter, difference_c_inter)"
      ],
      "metadata": {
        "id": "wxoyPxDiDS9K"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count vowels per utterance after matching\n",
        "# output 1: df of size \"interview minus cut vowel rows\", with an updated #vowels per utterance for each row (redundant for BG)\n",
        "# output 2: df of size \"len(Group)\" (2), that contains average # vowels per breath group for PWS group vs. Control group after matching\n",
        "[post_interview_vowels, post_interview_vowel_avg]  = count_vowels(matched_vowels_inter)\n",
        "[post_reading_vowels, post_reading_vowel_avg]  = count_vowels(matched_vowels_read)"
      ],
      "metadata": {
        "id": "q8oVGoIbDWsl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average # vowels per breath group for each participant after matching\n",
        "post_interview_participant_vowels_avg = participant_vowel_avg(post_interview_vowels)\n",
        "post_reading_participant_vowels_avg = participant_vowel_avg(post_reading_vowels)\n",
        "# only control group has been changed\n",
        "post_interview_participant_vowels_avg = post_interview_participant_vowels_avg[18:30]\n",
        "post_reading_participant_vowels_avg = post_reading_participant_vowels_avg[18:30]\n",
        "# combine with pre_matching (unchanged pws)avgs\n",
        "post_interview_participant_vowels_avg = interview_participant_vowel_avg[0:18].append(post_interview_participant_vowels_avg)\n",
        "post_reading_participant_vowels_avg = reading_participant_vowel_avg[0:18].append(post_reading_participant_vowels_avg)"
      ],
      "metadata": {
        "id": "73nTBNgTDXiK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count consonants per utterance after matching\n",
        "# output 1: df of size \"interview minus cut consonant rows\", with an updated #consonants per utterance for each row (redundant for BG)\n",
        "# output 2: df of size \"len(Group)\" (2), that contains average # consonants per breath group for PWS group vs. Control group after matching \n",
        "[post_interview_consonants, post_interview_consonant_avg]  = count_consonants(matched_consonants_inter)\n",
        "[post_reading_consonants, post_reading_consonant_avg]  = count_consonants(matched_consonants_read)"
      ],
      "metadata": {
        "id": "sRXtgmpoDfxo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # consonants per breath group for each participant after matching\n",
        "post_interview_participant_cons_avg = participant_consonant_avg(post_interview_consonants)\n",
        "post_reading_participant_cons_avg = participant_consonant_avg(post_reading_consonants)\n",
        "# only control group has been changed\n",
        "post_interview_participant_cons_avg = post_interview_participant_cons_avg[18:30]\n",
        "post_reading_participant_cons_avg = post_reading_participant_cons_avg[18:30]\n",
        "# combine with pre_matching (unchanged pws)avgs\n",
        "post_interview_participant_cons_avg = interview_participant_cons_avg[0:18].append(post_interview_participant_cons_avg)\n",
        "post_reading_participant_cons_avg = reading_participant_cons_avg[0:18].append(post_reading_participant_cons_avg)"
      ],
      "metadata": {
        "id": "4tPGFLpiDlGG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance\n",
        "[string1, string2, string3, string4, pws_v_inter, pws_c_inter, difference_v_inter, difference_c_inter] = compare_groups(post_interview_participant_vowels_avg, post_interview_participant_cons_avg)\n",
        "\n",
        "print(string1)\n",
        "print(string2)\n",
        "print(string3)\n",
        "print(string4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoDZPrQHF24-",
        "outputId": "1bb6d635-6968-4fea-dc13-7499a1ee5e23"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 7.87 syllables per utterance, while control participants produced 7.82 syllables on average.\n",
            "This means that on average control participants produced -0.05 syllables more per utterance.\n",
            "\n",
            "PWS produced on average 11.59 consonants per utterance, while control participants produced 11.44 consonants on average.\n",
            "This means that on average control participants produced -0.15 consonants more per utterance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[string5, string6, string7, string8, control_v_read, pws_v_read, difference_v_read, difference_c_read] = compare_groups(post_reading_participant_vowels_avg, post_reading_participant_cons_avg)\n",
        "print(string5)\n",
        "print(string6)\n",
        "print(string7)\n",
        "print(string8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdN7rC0OgV5-",
        "outputId": "945559ea-7119-4ac7-8f76-832ecef6c501"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 8.54 syllables per utterance, while control participants produced 8.37 syllables on average.\n",
            "This means that on average control participants produced -0.17 syllables more per utterance.\n",
            "\n",
            "PWS produced on average 13.13 consonants per utterance, while control participants produced 13.43 consonants on average.\n",
            "This means that on average control participants produced 0.31 consonants more per utterance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test if average number of vowels per breathgroup is still significantly different between groups after matching\n",
        "string1 = ttest_vowelDifference(post_interview_participant_vowels_avg, difference_v_inter)\n",
        "print(string1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilqOeJnsGEbp",
        "outputId": "d90abb56-a7e2-487e-d3f2-6713b99c855b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control utterances that were longer than the mean average length of PWS utterances were shortened. \n",
            "After matching, PWS had 7.87 vowels per utterance, while control participants had 7.82 per utterance. \n",
            "The difference is reduced to 0.05, which is statistically insignificant (p = 0.93).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string2 = ttest_vowelDifference(post_reading_participant_vowels_avg, difference_v_read)\n",
        "print(string2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tagTdgUzghPb",
        "outputId": "fdfaab3f-8e8d-43c9-b87b-7577aaf84874"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control utterances that were longer than the mean average length of PWS utterances were shortened. \n",
            "After matching, PWS had 8.54 vowels per utterance, while control participants had 8.37 per utterance. \n",
            "The difference is reduced to 0.17, which is statistically insignificant (p = 0.73).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test if average number of consonants per breathgroup is still significantly different between groups after matching\n",
        "string1 = ttest_conDifference(post_interview_participant_cons_avg, difference_c_inter)\n",
        "print(string1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu1kM6W6ZKR1",
        "outputId": "d7213f6b-88e1-40da-c97f-2cd3b5314227"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control utterances that were longer than the mean average length of PWS utterances, were shortened by 0 consonants. \n",
            "After matching, PWS had 11.59 consonants per utterance, while control participants had 11.44 per utterance. \n",
            "The difference is reduced to 0.15, which is statistically insignificant (p = 0.87).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string2 = ttest_conDifference(post_reading_participant_cons_avg, difference_c_read)\n",
        "print(string2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwNl3RnehBfT",
        "outputId": "41640835-8dd5-4cd9-90d8-dc8d7361ed6c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control utterances that were longer than the mean average length of PWS utterances, were shortened by 0 consonants. \n",
            "After matching, PWS had 13.13 consonants per utterance, while control participants had 13.43 per utterance. \n",
            "The difference is reduced to 0.31, which is statistically insignificant (p = 0.68).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Export Results**"
      ],
      "metadata": {
        "id": "LSBRBItTUrBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Create Output DataFrames**"
      ],
      "metadata": {
        "id": "IL6SwYg6WqA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading vowels\n",
        "pws = reading_vowels[reading_vowels[\"Group\"] == \"PWS\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "post_reading_vowels.drop([\"Unmached_Vowels\"],axis=1 , inplace = True)\n",
        "reading_vowels_matched = pws.append(post_reading_vowels)"
      ],
      "metadata": {
        "id": "TluS962eXBXf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interview vowels\n",
        "pws = interview_vowels[interview_vowels[\"Group\"] == \"PWS\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "post_interview_vowels.drop([\"Unmached_Vowels\"],axis=1 , inplace = True)\n",
        "interview_vowels_matched = pws.append(post_interview_vowels)"
      ],
      "metadata": {
        "id": "xKGxiIw3XBQf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading consonants\n",
        "pws = reading_consonants[reading_consonants[\"Group\"] == \"PWS\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "post_reading_consonants.drop([\"Unmatched_Cons\"],axis=1 , inplace = True)\n",
        "reading_consonants_matched = pws.append(post_reading_consonants)"
      ],
      "metadata": {
        "id": "cBHrZXjRUn-q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interview consonants\n",
        "pws = interview_consonants[interview_consonants[\"Group\"] == \"PWS\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "post_interview_consonants.drop([\"Unmatched_Cons\"],axis=1 , inplace = True)\n",
        "interview_consonants_matched = pws.append(post_interview_consonants)"
      ],
      "metadata": {
        "id": "jZ1AjImjWvYo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Create Directory and Save**"
      ],
      "metadata": {
        "id": "T-J1Fp7iXn9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUpmq0dfXrec",
        "outputId": "7d7e83f1-1b7f-4258-f93d-7c6225461d5d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/RhythmAnalysisPipeline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"3.MLU_Matched\"\n",
        "\n",
        "if os.path.exists(dir) == False:\n",
        "  os.mkdir(dir)"
      ],
      "metadata": {
        "id": "jwD2ACK5XrW8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline/3.MLU_Matched/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0-KpCC9XrTV",
        "outputId": "b50e3bd2-e11a-4e60-c4b9-33cfa6b66414"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/RhythmAnalysisPipeline/3.MLU_Matched\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_vowels_matched.to_excel(\"interview_TextGrid_comb_BG_vowelsMatched.xlsx\")\n",
        "interview_consonants_matched.to_excel(\"interview_TextGrid_comb_BG_consonantsMatched.xlsx\")\n",
        "reading_vowels_matched.to_excel(\"reading_TextGrid_comb_BG_vowelsMatched.xlsx\")\n",
        "reading_consonants_matched.to_excel(\"reading_TextGrid_comb_BG_consonantsMatched.xlsx\")"
      ],
      "metadata": {
        "id": "-EXbZpb6XrPf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKJAanosXrIv",
        "outputId": "c0206f3a-c56c-4f63-bf41-f524e5d3765d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/RhythmAnalysisPipeline\n"
          ]
        }
      ]
    }
  ]
}