{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Match_MLU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPnSlwM2XKEvtNcjy0SbSJB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janina712/MLTSA22_JBoecher/blob/main/Other/3.%20Match_MLU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0. Import & Set-Up**"
      ],
      "metadata": {
        "id": "y5foIPlFYxCF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oeyduNDx-Fn4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import os\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjhQ3dDP-KVJ",
        "outputId": "66370b95-39b4-4be8-e802-2cacba587943"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline/2.BreathGroups_Assigned/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTr2gWXQ-Mob",
        "outputId": "f98dc181-038d-4d14-91e2-4e81652192fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/RhythmAnalysisPipeline/2.BreathGroups_Assigned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reading = pd.read_excel(\"reading_TextGrid_comb_BG_loop.xlsx\")\n",
        "interview = pd.read_excel(\"interview_TextGrid_comb_BG_loop.xlsx\")"
      ],
      "metadata": {
        "id": "auwA6jOU-MhK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IDs = ['24fa', '24ma', '24mb', '26f', '29ma', '29mb', '29mc', '32m', '34m', '35mb', '46ma', '50fa', '50fb', '54f', '57m', '60m', '62f', '62m','C1_DS', 'C2_JH', 'C3_MD', 'C4_ZO', 'C5_HL', 'C6_LH', 'C7_SH', 'C9_RD',  'C10_KS', 'C11_NP', 'C12_CC', 'C13_RG']"
      ],
      "metadata": {
        "id": "74SKf1v8-Q39"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subj_col = pd.DataFrame(['24fa', '24ma', '24mb', '26f', '29ma', '29mb', '29mc', '32m', '34m', '35mb', '46ma', '50fa', '50fb', '54f', '57m', '60m', '62f', '62m','C1_DS', 'C2_JH', 'C3_MD', 'C4_ZO', 'C5_HL', 'C6_LH', 'C7_SH', 'C9_RD', 'C10_KS', 'C11_NP', 'C12_CC', 'C13_RG'], columns = [\"ID\"])"
      ],
      "metadata": {
        "id": "PrO6jatX-V3U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "control_IDs = ['C1_DS', 'C2_JH', 'C3_MD', 'C4_ZO', 'C5_HL', 'C6_LH', 'C7_SH', 'C9_RD', 'C10_KS', 'C11_NP', 'C12_CC', 'C13_RG']"
      ],
      "metadata": {
        "id": "CBE0iJrx-Zii"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Functions**"
      ],
      "metadata": {
        "id": "6TyIAixsYuCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Assign Participant Group**"
      ],
      "metadata": {
        "id": "NL_9tczv-cbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_group(df):\n",
        "  group = pd.DataFrame(index = range(len(df)),columns=[\"Group\"])\n",
        "\n",
        "  for i in range(0,len(df)):\n",
        "    if \"_\" in df[\"ID\"][i]:\n",
        "      group[\"Group\"][i] = \"Control\"\n",
        "    else:\n",
        "      group[\"Group\"][i] = \"PWS\"\n",
        "  \n",
        "  df_out = pd.concat([ group, df], axis=1)\n",
        "  df_out = df_out[df_out.Type != \"silence\"]\n",
        "  df_out.index = range(len(df_out.index))\n",
        "  df_out.drop(['Unnamed: 0'], axis=1 , inplace = True)\n",
        "  return(df_out)"
      ],
      "metadata": {
        "id": "5bEE4RA0-fhj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Count Vowels**"
      ],
      "metadata": {
        "id": "BIs6iaUh-jLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_vowels(df):  \n",
        "  df_vowels = df[df[\"Type\"]  == \"vowel\"] \n",
        "  df_vowels.index = range(len(df_vowels.index))\n",
        "\n",
        "  syll_col = pd.DataFrame()  ## initialize group-level dataframe\n",
        "  for ID in IDs: ## loop over participnts\n",
        "    syll_current_ID = pd.DataFrame()   ## initialize participant-level dataframe\n",
        "    subset_sounds = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_sounds.index = range(len(subset_sounds.index)) # reset index\n",
        "    subset_vowels = subset_sounds[subset_sounds[\"Type\"] == \"vowel\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_vowels.index = range(len(subset_vowels.index)) # reset index\n",
        "    syll = subset_vowels[\"Breath.Group\"].value_counts().sort_index() # count how often a certain Breath group occurs for this participant\n",
        "    syll.index = range(len(syll.index)) # reset index\n",
        "    for a in range (0,len(syll)): # go through all breath groups that this participant produced\n",
        "      syll_current_BG = pd.DataFrame()  ## initialize BG-level dataframe\n",
        "      syll_current_BG = pd.DataFrame(np.repeat(syll.iloc[a], syll.iloc[a], axis=0)) #replicate the sum sum times\n",
        "      syll_current_ID = syll_current_ID.append([syll_current_BG], ignore_index = True) # add BG-level dataframe to participant-level dataframe \n",
        "    syll_col = syll_col.append([syll_current_ID], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "\n",
        "  df_vowels = pd.concat([df_vowels, syll_col], axis=1)\n",
        "  #df_vowels.drop(['Syllables'], axis=1 , inplace = True)\n",
        "  df_vowels.rename(columns = {'Syllables':'Unmached_Vowels'}, inplace = True)\n",
        "  df_vowels.rename(columns = {0:'Syllables'}, inplace = True) # rename new column\n",
        "  pre_df_vowel_avg = df_vowels.groupby(\"Group\").mean()    ########### average counting 13 13 times\n",
        "\n",
        "  return(df_vowels, pre_df_vowel_avg)"
      ],
      "metadata": {
        "id": "GU5KQG89-n0k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Count Consonants**"
      ],
      "metadata": {
        "id": "_fjALDDM-uKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_consonants(df):  \n",
        "  df_consonants = df[df[\"Type\"]  == \"consonant\"] \n",
        "  df_consonants.index = range(len(df_consonants.index))\n",
        "\n",
        "  con_col = pd.DataFrame()  ## initialize group-level dataframe\n",
        "  for ID in IDs: ## loop over participnts\n",
        "    con_current_ID = pd.DataFrame()   ## initialize participant-level dataframe\n",
        "    subset_sounds = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_sounds.index = range(len(subset_sounds.index)) # reset index\n",
        "    subset_cons = subset_sounds[subset_sounds[\"Type\"] == \"consonant\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_cons.index = range(len(subset_cons.index)) # reset index\n",
        "    con = subset_cons[\"Breath.Group\"].value_counts().sort_index() # count how often a certain Breath group occurs for this participant\n",
        "    con.index = range(len(con.index)) # reset index\n",
        "    for a in range (0,len(con)): # go through all breath groups that this participant produced\n",
        "      con_current_BG = pd.DataFrame()  ## initialize BG-level dataframe\n",
        "      con_current_BG = pd.DataFrame(np.repeat(con.iloc[a], con.iloc[a], axis=0)) #replicate the sum sum times\n",
        "      con_current_ID = con_current_ID.append([con_current_BG], ignore_index = True) # add BG-level dataframe to participant-level dataframe \n",
        "    con_col = con_col.append([con_current_ID], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "\n",
        "  df_consonants = pd.concat([df_consonants, con_col], axis=1)\n",
        "  #df_consonants.drop(['Consonants'], axis=1 , inplace = True)\n",
        "  df_consonants.rename(columns = {'Consonants':'Unmatched_Cons'}, inplace = True)\n",
        "  df_consonants.rename(columns = {0:'Consonants'}, inplace = True) # rename new column\n",
        "  pre_df_consonant_avg = df_consonants.groupby(\"Group\").mean()    ########### average counting 13 13 times\n",
        "\n",
        "  return(df_consonants, pre_df_consonant_avg)"
      ],
      "metadata": {
        "id": "3rHV1y7h-xio"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Average Vowel Count by Participant**"
      ],
      "metadata": {
        "id": "HNK9tHE8-7vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def participant_vowel_avg(df):  \n",
        "  group_col = pd.DataFrame(index = range(len(subj_col)),columns=[\"Group\"])\n",
        "  for i in range(0,len(group_col)):\n",
        "    if \"_\" in subj_col[\"ID\"][i]:\n",
        "      group_col[\"Group\"][i] = \"Control\"\n",
        "    else:\n",
        "      group_col[\"Group\"][i] = \"PWS\"\n",
        "  \n",
        "  n = -1\n",
        "  avg_col = pd.DataFrame(index = range(len(subj_col)),columns=[\"Syllables\"])\n",
        "  for ID in IDs: ## loop over participnts\n",
        "    n = n + 1\n",
        "    subset_BGs = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "    BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "    subj_avg = BG_avg[\"Syllables\"].mean()\n",
        "    avg_col[\"Syllables\"][n] = subj_avg\n",
        "\n",
        "  df_participant_vowel_avg = pd.concat([group_col, subj_col, avg_col], axis=1)\n",
        "\n",
        "  return(df_participant_vowel_avg)"
      ],
      "metadata": {
        "id": "ThtJbCxy_Ah0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Average Consonant Count by Participant**"
      ],
      "metadata": {
        "id": "HeiTsry4_IEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def participant_consonant_avg(df):  \n",
        "  group_col = pd.DataFrame(index = range(len(subj_col)),columns=[\"Group\"])\n",
        "  for i in range(0,len(group_col)):\n",
        "    if \"_\" in subj_col[\"ID\"][i]:\n",
        "      group_col[\"Group\"][i] = \"Control\"\n",
        "    else:\n",
        "      group_col[\"Group\"][i] = \"PWS\"\n",
        "  \n",
        "  n = -1\n",
        "  avg_col = pd.DataFrame(index = range(len(subj_col)),columns=[\"Consonants\"])\n",
        "  for ID in IDs: ## loop over participnts\n",
        "    n = n + 1\n",
        "    subset_BGs = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "    BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "    subj_avg = BG_avg[\"Consonants\"].mean()\n",
        "    avg_col[\"Consonants\"][n] = subj_avg\n",
        "\n",
        "  df_participant_cons_avg = pd.concat([group_col, subj_col, avg_col], axis=1)\n",
        "\n",
        "  return(df_participant_cons_avg)"
      ],
      "metadata": {
        "id": "0YgGSmaY_L_L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Vowel to Consonant Ratio**"
      ],
      "metadata": {
        "id": "E0-UaQZpKasN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Ratio(condition, df_vowels_pws, df_consonants_pws, df_vowels_control, df_consonants_control):\n",
        "  vowel_perc_p = df_vowels_pws[df_vowels_pws[\"Group\"] == \"PWS\"]\n",
        "  consonant_perc_p = df_consonants_pws[df_consonants_pws[\"Group\"] == \"PWS\"]\n",
        "  vowel_perc_c = df_vowels_control[df_vowels_control[\"Group\"] == \"Control\"]\n",
        "  consonant_perc_c = df_consonants_control[df_consonants_control[\"Group\"] == \"Control\"]\n",
        "\n",
        "  vowel_ratio_p = len(vowel_perc_p)/(len(vowel_perc_p) + len(consonant_perc_p))\n",
        "  vowel_ratio_c = len(vowel_perc_c)/(len(vowel_perc_c) + len(consonant_perc_c))\n",
        "\n",
        "  string = (f\"Before matching, PWS have {round(vowel_ratio_p,4)*100}% vowels and Control have {round(vowel_ratio_c,4)*100}% vowels in their {condition} utterances. This ratio is a measure of number of vowels.\")\n",
        "  print(string)\n",
        "  return(string)"
      ],
      "metadata": {
        "id": "Cqr76EowIuVz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Compare Consonant and Vowel Counts Across Participant Groups (PWS vs. Control)**"
      ],
      "metadata": {
        "id": "s-TyNdAN_SA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_groups(df_vowels, df_consonants):\n",
        "  control_v = (df_vowels.groupby(\"ID\").mean()[\"Syllables\"][18:30]).mean()\n",
        "  pws_v = (df_vowels.groupby(\"ID\").mean()[\"Syllables\"][0:18]).mean()\n",
        "  difference_v = control_v - pws_v\n",
        "\n",
        "  control_c = (df_consonants.groupby(\"ID\").mean()[\"Consonants\"][18:30]).mean()\n",
        "  pws_c = (df_consonants.groupby(\"ID\").mean()[\"Consonants\"][0:18]).mean()\n",
        "  difference_c = control_c - pws_c\n",
        "\n",
        "  string1 = (f\"PWS produced on average {round(pws_v,2)} syllables per utterance, while control participants produced {round(control_v,2)} syllables on average.\")\n",
        "  string2 = (f\"This means that on average control participants produced {round(difference_v,2)} syllables more per utterance.\")\n",
        "  string3 = (f\"\\nPWS produced on average {round(pws_c,2)} consonants per utterance, while control participants produced {round(control_c,2)} consonants on average.\")\n",
        "  string4 = (f\"This means that on average control participants produced {round(difference_c,2)} consonants more per utterance.\")\n",
        "\n",
        "  return(string1, string2, string3, string4, pws_v, pws_c, difference_v, difference_c)"
      ],
      "metadata": {
        "id": "a9ZYa7rp_ZKl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Match Number of Vowels Per Utterance**"
      ],
      "metadata": {
        "id": "lYx6TnBZ_fBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match_vowels(df_vowels, pws_v, cut_v):\n",
        "  cut_v = math.ceil(cut_v) ##+ 5                                                           \n",
        "  syll_col_matched = pd.DataFrame()  ## initialize group-level dataframe              \n",
        "  participant = pd.DataFrame()  ## initialize participant-level dataframe\n",
        "  df_control = df_vowels[df_vowels[\"Group\"]  == \"Control\"] \n",
        "  df_control.index = range(len(df_control.index)) ## group\n",
        "  for ID in control_IDs:\n",
        "    df_control_ID = df_control[df_control[\"ID\"]  == ID] \n",
        "    df_control_ID.index = range(len(df_control_ID.index))  ### person\n",
        "    BGs = df_control_ID[\"Breath.Group\"].unique()\n",
        "    for i in range(0,len(BGs)):\n",
        "      df_control_ID_BG = df_control_ID[df_control_ID[\"Breath.Group\"]  == i] \n",
        "      df_control_ID_BG.index = range(len(df_control_ID_BG.index)) ## BG\n",
        "      if len(df_control_ID_BG) >= cut_v:\n",
        "        df_control_ID_BG.drop(df_control_ID_BG.tail(cut_v).index, inplace = True) \n",
        "        participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "      else:  \n",
        "        participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "  syll_col_matched = syll_col_matched.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "\n",
        "  return(syll_col_matched)"
      ],
      "metadata": {
        "id": "uoetWRx4_jWh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Match Number of Consonants Per Utterance**"
      ],
      "metadata": {
        "id": "gNAmLl8E_nAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match_consonants(df_consonants, pws_c, cut_c):\n",
        "  cut_c = math.ceil(cut_c) ##+ 4                                                       \n",
        "  cons_col_matched = pd.DataFrame()  ## initialize group-level dataframe         \n",
        "  participant = pd.DataFrame()  ## initialize participant-level dataframe\n",
        "  df_control = df_consonants[df_consonants[\"Group\"]  == \"Control\"] \n",
        "  df_control.index = range(len(df_control.index)) ## group\n",
        "  for ID in control_IDs:\n",
        "    df_control_ID = df_control[df_control[\"ID\"]  == ID] \n",
        "    df_control_ID.index = range(len(df_control_ID.index))  ### person\n",
        "    BGs = df_control_ID[\"Breath.Group\"].unique()\n",
        "    for i in range(0,len(BGs)):\n",
        "      df_control_ID_BG = df_control_ID[df_control_ID[\"Breath.Group\"]  == i] \n",
        "      df_control_ID_BG.index = range(len(df_control_ID_BG.index)) ## BG\n",
        "      if len(df_control_ID_BG) >= cut_c:\n",
        "        df_control_ID_BG.drop(df_control_ID_BG.tail(cut_c).index, inplace = True) \n",
        "        participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "      else:  \n",
        "        participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "  cons_col_matched = cons_col_matched.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "  return(cons_col_matched)"
      ],
      "metadata": {
        "id": "2dxTzRVg_q2P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Test if Remaining Vowel Difference Between Groups is Statistically Significant**"
      ],
      "metadata": {
        "id": "_jIp8xeYAyBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ttest_vowelDifference(matched_participant_df, cut_v): \n",
        "  cut_v = round(cut_v)\n",
        "  ttest_control = matched_participant_df[18:30]  \n",
        "  ttest_pws = matched_participant_df[0:18]   \n",
        "\n",
        "  control_v =  matched_participant_df[18:30].mean()[0]\n",
        "  pws_v =  matched_participant_df[0:18].mean()[0]\n",
        "\n",
        "  difference_v_matched = control_v - pws_v\n",
        "\n",
        "  df_v_matched_test = stats.ttest_ind(ttest_control['Syllables'],\n",
        "                        ttest_pws['Syllables'])\n",
        "  if df_v_matched_test[1] >= 0.05:\n",
        "    level = \"insignificant\"\n",
        "  else:\n",
        "    level = \"significant\"\n",
        "  string11 = (f\"Control utterances that were longer than the mean average length of PWS utterances were shortened. \\nAfter matching, PWS had {round(pws_v,2)} vowels per utterance, while control participants had {round(control_v,2)} per utterance. \\nThe difference is reduced to {abs(round(difference_v_matched,2))}, which is statistically {level} (p = {round(df_v_matched_test[1],2)}).\")\n",
        "\n",
        "  return(string11)"
      ],
      "metadata": {
        "id": "Qpkmbv1dA48L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Test if Remaining Consonant Difference Between Groups is Statistically Significant**"
      ],
      "metadata": {
        "id": "oB_v2Do5_-T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ttest_conDifference(matched_participant_df, cut_c):  \n",
        "  cut_c = round(cut_c)\n",
        "  ttest_control = matched_participant_df[18:30]\n",
        "  ttest_pws = matched_participant_df[0:18]  \n",
        "\n",
        "  control_c =  matched_participant_df[18:30].mean()[0]\n",
        "  pws_c =  matched_participant_df[0:18].mean()[0]\n",
        "\n",
        "  difference_c_matched = control_c - pws_c\n",
        "\n",
        "  df_c_matched_test = stats.ttest_ind(ttest_control['Consonants'],\n",
        "                        ttest_pws['Consonants'])\n",
        "  if df_c_matched_test[1] >= 0.05:\n",
        "    level = \"insignificant\"\n",
        "  else:\n",
        "    level = \"significant\"\n",
        "  string11 = (f\"Control utterances that were longer than the mean average length of PWS utterances, were shortened by {round(cut_c,2)} consonants. \\nAfter matching, PWS had {round(pws_c,2)} consonants per utterance, while control participants had {round(control_c,2)} per utterance. \\nThe difference is reduced to {abs(round(difference_c_matched,2))}, which is statistically {level} (p = {round(df_c_matched_test[1],2)}).\")\n",
        "\n",
        "  return(string11)"
      ],
      "metadata": {
        "id": "kOkbDbKdAIrv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conduct Matching Analysis using Functions**"
      ],
      "metadata": {
        "id": "IS9fvIXABWV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add new column to dataframe that denotes participant's group membership (PWS vs. Control)\n",
        "interview = assign_group(interview)\n",
        "reading = assign_group(reading)"
      ],
      "metadata": {
        "id": "5Wy0bBQKB9bJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count vowels per utterance \n",
        "# output 1: df of size \"interview\", with an additional #vowels per utterance for each row (redundant for BG)\n",
        "# output 2: df of size \"len(Group)\" (2), that contains average # vowels per breath group for PWS group vs. Control group \n",
        "[interview_vowels, pre_interview_vowel_avg]  = count_vowels(interview)\n",
        "[reading_vowels, pre_reading_vowel_avg] = count_vowels(reading)"
      ],
      "metadata": {
        "id": "WoVGC2FECtmO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count consonants per utterance \n",
        "# output 1: df of size \"interview\", with an additional #consonants per utterance for each row (redundant for BG)\n",
        "# output 2: df of size \"len(Group)\" (2), that contains average # consonants per breath group for PWS group vs. Control group \n",
        "[interview_consonants, pre_interview_consonant_avg]  = count_consonants(interview)\n",
        "[reading_consonants, pre_reading_consonants_avg] = count_consonants(reading)"
      ],
      "metadata": {
        "id": "8Qlw9EVdCva6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # vowels per breath group for each participant \n",
        "interview_participant_vowel_avg = participant_vowel_avg(interview_vowels)\n",
        "reading_participant_vowel_avg = participant_vowel_avg(reading_vowels)"
      ],
      "metadata": {
        "id": "3KtyX_nPCy8X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # consonants per breath group for each participant \n",
        "interview_participant_cons_avg = participant_consonant_avg(interview_consonants)\n",
        "reading_participant_cons_avg = participant_consonant_avg(reading_consonants)"
      ],
      "metadata": {
        "id": "rXQnEwfrC6wn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a string that contains the percentage of vowels in dataframe\n",
        "pre_matching_reading  = get_Ratio(\"reading\", reading_vowels, reading_consonants, reading_vowels, reading_consonants)\n",
        "pre_matching_interview  = get_Ratio(\"interview\", interview_vowels, interview_consonants, interview_vowels, interview_consonants)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTY7UtxZJrFJ",
        "outputId": "70877984-c4d8-4a45-b24b-f4efb7cebfe3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before matching, PWS have 39.43% vowels and Control have 39.45% vowels in their reading utterances. This ratio is a measure of number of vowels.\n",
            "Before matching, PWS have 40.37% vowels and Control have 39.07% vowels in their interview utterances. This ratio is a measure of number of vowels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance \n",
        "# interview\n",
        "string1, string2, string3, string4, pws_v_inter, pws_c_inter, difference_v_inter, difference_c_inter = compare_groups(interview_participant_vowel_avg, interview_participant_cons_avg)\n",
        "\n",
        "print(string1)\n",
        "print(string2)\n",
        "print(string3)\n",
        "print(string4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L2XWvlnC-8_",
        "outputId": "71ddef78-6c7d-4ddb-9809-3bddd6676112"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 7.81 syllables per utterance, while control participants produced 9.7 syllables on average.\n",
            "This means that on average control participants produced 1.9 syllables more per utterance.\n",
            "\n",
            "PWS produced on average 11.49 consonants per utterance, while control participants produced 15.17 consonants on average.\n",
            "This means that on average control participants produced 3.68 consonants more per utterance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance \n",
        "# reading\n",
        "string5, string6, string7, string8, pws_v_read, pws_c_read, difference_v_read, difference_c_read  = compare_groups(reading_participant_vowel_avg, reading_participant_cons_avg)\n",
        "\n",
        "print(string5)\n",
        "print(string6)\n",
        "print(string7)\n",
        "print(string8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Ace-XrICeI",
        "outputId": "d9b03ce8-821e-43ae-853b-6049ef06e54b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 8.3 syllables per utterance, while control participants produced 11.4 syllables on average.\n",
            "This means that on average control participants produced 3.1 syllables more per utterance.\n",
            "\n",
            "PWS produced on average 12.75 consonants per utterance, while control participants produced 17.49 consonants on average.\n",
            "This means that on average control participants produced 4.74 consonants more per utterance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# match number of vowels per utterance by cutting long control utterances by the difference in average vowel number between groups\n",
        "matched_vowels_read = match_vowels(reading_vowels,pws_v_read, difference_v_read)\n",
        "matched_vowels_inter = match_vowels(interview_vowels, pws_v_inter, difference_v_inter)"
      ],
      "metadata": {
        "id": "rH720-ZrDDZy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# match number of consonants per utterance by cutting long control utterances by the difference in average consonant number between groups\n",
        "matched_consonants_read = match_vowels(reading_consonants,pws_c_read, difference_c_read)\n",
        "matched_consonants_inter = match_vowels(interview_consonants, pws_c_inter, difference_c_inter)"
      ],
      "metadata": {
        "id": "wxoyPxDiDS9K"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count vowels per utterance after matching\n",
        "# output 1: df of size \"interview minus cut vowel rows\", with an updated #vowels per utterance for each row (redundant for BG)\n",
        "# output 2: df of size \"len(Group)\" (2), that contains average # vowels per breath group for PWS group vs. Control group after matching\n",
        "[post_interview_vowels, post_interview_vowel_avg]  = count_vowels(matched_vowels_inter)\n",
        "[post_reading_vowels, post_reading_vowel_avg]  = count_vowels(matched_vowels_read)"
      ],
      "metadata": {
        "id": "q8oVGoIbDWsl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average # vowels per breath group for each participant after matching\n",
        "post_interview_participant_vowels_avg = participant_vowel_avg(post_interview_vowels)\n",
        "post_reading_participant_vowels_avg = participant_vowel_avg(post_reading_vowels)\n",
        "# only control group has been changed\n",
        "post_interview_participant_vowels_avg = post_interview_participant_vowels_avg[18:30]\n",
        "post_reading_participant_vowels_avg = post_reading_participant_vowels_avg[18:30]\n",
        "# combine with pre_matching (unchanged pws)avgs\n",
        "post_interview_participant_vowels_avg = interview_participant_vowel_avg[0:18].append(post_interview_participant_vowels_avg)\n",
        "post_reading_participant_vowels_avg = reading_participant_vowel_avg[0:18].append(post_reading_participant_vowels_avg)"
      ],
      "metadata": {
        "id": "73nTBNgTDXiK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count consonants per utterance after matching\n",
        "# output 1: df of size \"interview minus cut consonant rows\", with an updated #consonants per utterance for each row (redundant for BG)\n",
        "# output 2: df of size \"len(Group)\" (2), that contains average # consonants per breath group for PWS group vs. Control group after matching \n",
        "[post_interview_consonants, post_interview_consonant_avg]  = count_consonants(matched_consonants_inter)\n",
        "[post_reading_consonants, post_reading_consonant_avg]  = count_consonants(matched_consonants_read)"
      ],
      "metadata": {
        "id": "sRXtgmpoDfxo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # consonants per breath group for each participant after matching\n",
        "post_interview_participant_cons_avg = participant_consonant_avg(post_interview_consonants)\n",
        "post_reading_participant_cons_avg = participant_consonant_avg(post_reading_consonants)\n",
        "# only control group has been changed\n",
        "post_interview_participant_cons_avg = post_interview_participant_cons_avg[18:30]\n",
        "post_reading_participant_cons_avg = post_reading_participant_cons_avg[18:30]\n",
        "# combine with pre_matching (unchanged pws)avgs\n",
        "post_interview_participant_cons_avg = interview_participant_cons_avg[0:18].append(post_interview_participant_cons_avg)\n",
        "post_reading_participant_cons_avg = reading_participant_cons_avg[0:18].append(post_reading_participant_cons_avg)"
      ],
      "metadata": {
        "id": "4tPGFLpiDlGG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a string that contains the percentage of vowels in dataframe\n",
        "post_matching_reading  = get_Ratio(\"reading\", reading_vowels, reading_consonants, post_reading_vowels, post_reading_consonants)\n",
        "post_matching_interview  = get_Ratio(\"interview\", interview_vowels, interview_consonants, post_interview_vowels, post_interview_consonants)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1rkZc9MKICW",
        "outputId": "7bbef254-73e1-47ec-f4af-46476d635823"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before matching, PWS have 39.43% vowels and Control have 37.3% vowels in their reading utterances. This ratio is a measure of number of vowels.\n",
            "Before matching, PWS have 40.37% vowels and Control have 40.910000000000004% vowels in their interview utterances. This ratio is a measure of number of vowels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance\n",
        "[string1, string2, string3, string4, pws_v_inter, pws_c_inter, difference_v_inter, difference_c_inter] = compare_groups(post_interview_participant_vowels_avg, post_interview_participant_cons_avg)\n",
        "\n",
        "print(string1)\n",
        "print(string2)\n",
        "print(string3)\n",
        "print(string4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoDZPrQHF24-",
        "outputId": "30d36762-3e2d-4426-bc82-50f17a08c630"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 7.81 syllables per utterance, while control participants produced 7.69 syllables on average.\n",
            "This means that on average control participants produced -0.12 syllables more per utterance.\n",
            "\n",
            "PWS produced on average 11.49 consonants per utterance, while control participants produced 11.25 consonants on average.\n",
            "This means that on average control participants produced -0.23 consonants more per utterance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[string5, string6, string7, string8, control_v_read, pws_v_read, difference_v_read, difference_c_read] = compare_groups(post_reading_participant_vowels_avg, post_reading_participant_cons_avg)\n",
        "print(string5)\n",
        "print(string6)\n",
        "print(string7)\n",
        "print(string8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdN7rC0OgV5-",
        "outputId": "399eb2ea-629b-417c-e7a0-834768cd32c8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 8.3 syllables per utterance, while control participants produced 7.94 syllables on average.\n",
            "This means that on average control participants produced -0.36 syllables more per utterance.\n",
            "\n",
            "PWS produced on average 12.75 consonants per utterance, while control participants produced 12.77 consonants on average.\n",
            "This means that on average control participants produced 0.02 consonants more per utterance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test if average number of vowels per breathgroup is still significantly different between groups after matching\n",
        "string1 = ttest_vowelDifference(post_interview_participant_vowels_avg, difference_v_inter)\n",
        "print(string1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilqOeJnsGEbp",
        "outputId": "33dc4c98-b127-4f50-8488-6c1ce644400e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control utterances that were longer than the mean average length of PWS utterances were shortened. \n",
            "After matching, PWS had 7.81 vowels per utterance, while control participants had 7.69 per utterance. \n",
            "The difference is reduced to 0.12, which is statistically insignificant (p = 0.84).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string2 = ttest_vowelDifference(post_reading_participant_vowels_avg, difference_v_read)\n",
        "print(string2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tagTdgUzghPb",
        "outputId": "97b7d811-1244-43e1-d65d-f556557e0054"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control utterances that were longer than the mean average length of PWS utterances were shortened. \n",
            "After matching, PWS had 8.3 vowels per utterance, while control participants had 7.94 per utterance. \n",
            "The difference is reduced to 0.36, which is statistically insignificant (p = 0.45).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test if average number of consonants per breathgroup is still significantly different between groups after matching\n",
        "string1 = ttest_conDifference(post_interview_participant_cons_avg, difference_c_inter)\n",
        "print(string1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu1kM6W6ZKR1",
        "outputId": "8b311af7-8e53-4346-8c22-d991617bc74d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control utterances that were longer than the mean average length of PWS utterances, were shortened by 0 consonants. \n",
            "After matching, PWS had 11.49 consonants per utterance, while control participants had 11.25 per utterance. \n",
            "The difference is reduced to 0.23, which is statistically insignificant (p = 0.79).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string2 = ttest_conDifference(post_reading_participant_cons_avg, difference_c_read)\n",
        "print(string2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwNl3RnehBfT",
        "outputId": "ccb50a89-05c5-4f8f-f4f8-58d66a5e6a4f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control utterances that were longer than the mean average length of PWS utterances, were shortened by 0 consonants. \n",
            "After matching, PWS had 12.75 consonants per utterance, while control participants had 12.77 per utterance. \n",
            "The difference is reduced to 0.02, which is statistically insignificant (p = 0.98).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Export Results**"
      ],
      "metadata": {
        "id": "0YGvxPp0D3zQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Create Output DataFrames**"
      ],
      "metadata": {
        "id": "u8sT3hMBD3jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading vowels\n",
        "pws = reading_vowels[reading_vowels[\"Group\"] == \"PWS\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "post_reading_vowels.drop([\"Unmached_Vowels\"],axis=1 , inplace = True)\n",
        "reading_vowels_matched = pws.append(post_reading_vowels)"
      ],
      "metadata": {
        "id": "l4IYo5LIDuoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interview vowels\n",
        "pws = interview_vowels[interview_vowels[\"Group\"] == \"PWS\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "post_interview_vowels.drop([\"Unmached_Vowels\"],axis=1 , inplace = True)\n",
        "interview_vowels_matched = pws.append(post_interview_vowels)"
      ],
      "metadata": {
        "id": "Nm7ZYNLsDvxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reading consonants\n",
        "pws = reading_consonants[reading_consonants[\"Group\"] == \"PWS\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "post_reading_consonants.drop([\"Unmatched_Cons\"],axis=1 , inplace = True)\n",
        "reading_consonants_matched = pws.append(post_reading_consonants)"
      ],
      "metadata": {
        "id": "h9UWHUADDvmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interview consonants\n",
        "pws = interview_consonants[interview_consonants[\"Group\"] == \"PWS\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "post_interview_consonants.drop([\"Unmatched_Cons\"],axis=1 , inplace = True)\n",
        "interview_consonants_matched = pws.append(post_interview_consonants)"
      ],
      "metadata": {
        "id": "8uMR9dwPDvaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Create Directory and Save**"
      ],
      "metadata": {
        "id": "MIwfWoUlD_Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline/"
      ],
      "metadata": {
        "id": "BIXFcjkyEFSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"3.MLU_Matched\"\n",
        "\n",
        "if os.path.exists(dir) == False:\n",
        "  os.mkdir(dir)"
      ],
      "metadata": {
        "id": "i75FxnopEFHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline/3.MLU_Matched/"
      ],
      "metadata": {
        "id": "qMk9NQWSEE_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interview_vowels_matched.to_excel(\"interview_TextGrid_comb_BG_vowelsMatched.xlsx\")\n",
        "interview_consonants_matched.to_excel(\"interview_TextGrid_comb_BG_consonantsMatched.xlsx\")\n",
        "reading_vowels_matched.to_excel(\"reading_TextGrid_comb_BG_vowelsMatched.xlsx\")\n",
        "reading_consonants_matched.to_excel(\"reading_TextGrid_comb_BG_consonantsMatched.xlsx\")"
      ],
      "metadata": {
        "id": "ab66fmQ1EE1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline/"
      ],
      "metadata": {
        "id": "p8OhIDnXEElv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Match Fluent vs. Disfluent**"
      ],
      "metadata": {
        "id": "ZR3A2pJJqGO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Divide dataframe by groups**"
      ],
      "metadata": {
        "id": "vn7QtNzHvUEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reading_vowels_pws = reading_vowels[reading_vowels[\"Group\"] == \"PWS\"]\n",
        "reading_vowels_pws.index = range(len(reading_vowels_pws.index))\n",
        "reading_vowels_control = reading_vowels[reading_vowels[\"Group\"] == \"Control\"]\n",
        "reading_vowels_control.index = range(len(reading_vowels_control.index))"
      ],
      "metadata": {
        "id": "_OcmeFEpsYQx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reading_consonants_pws = reading_consonants[reading_consonants[\"Group\"] == \"PWS\"]\n",
        "reading_consonants_pws.index = range(len(reading_consonants_pws.index))\n",
        "reading_consonants_control = reading_consonants[reading_consonants[\"Group\"] == \"Control\"]\n",
        "reading_consonants_control.index = range(len(reading_consonants_control.index))"
      ],
      "metadata": {
        "id": "UgtjPyg1tIzn"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get means for fluent and disfluent utterances for each group for reading**"
      ],
      "metadata": {
        "id": "X9UoqCZBvpSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading, pws\n",
        "fluent_v_r_p = reading_vowels_pws.groupby([\"FluencyStatus\"]).mean()[\"Syllables\"][1]\n",
        "disfluent_v_r_p = reading_vowels_pws.groupby([\"FluencyStatus\"]).mean()[\"Syllables\"][0]\n",
        "fluent_c_r_p = reading_consonants_pws.groupby([\"FluencyStatus\"]).mean()[\"Consonants\"][1]\n",
        "disfluent_c_r_p = reading_consonants_pws.groupby([\"FluencyStatus\"]).mean()[\"Consonants\"][0]"
      ],
      "metadata": {
        "id": "HRPSDFKFqKNJ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading, control\n",
        "fluent_v_r_c = reading_vowels_control.groupby([\"FluencyStatus\"]).mean()[\"Syllables\"][1]\n",
        "disfluent_v_r_c = reading_vowels_control.groupby([\"FluencyStatus\"]).mean()[\"Syllables\"][0]\n",
        "fluent_c_r_c = reading_consonants_control.groupby([\"FluencyStatus\"]).mean()[\"Consonants\"][1]\n",
        "disfluent_c_r_c = reading_consonants_control.groupby([\"FluencyStatus\"]).mean()[\"Consonants\"][0]"
      ],
      "metadata": {
        "id": "mm4X9xRltfqF"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Divide dataframe by groups**"
      ],
      "metadata": {
        "id": "SHSh30qRvgwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# interview vowel groups\n",
        "interview_vowels_pws = interview_vowels[interview_vowels[\"Group\"] == \"PWS\"]\n",
        "interview_vowels_pws.index = range(len(interview_vowels_pws.index))\n",
        "interview_vowels_control = interview_vowels[interview_vowels[\"Group\"] == \"Control\"]\n",
        "interview_vowels_control.index = range(len(interview_vowels_control.index))"
      ],
      "metadata": {
        "id": "oEUbhbwpuPxs"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interview consonant groups\n",
        "interview_consonants_pws = interview_consonants[interview_consonants[\"Group\"] == \"PWS\"]\n",
        "interview_consonants_pws.index = range(len(interview_consonants_pws.index))\n",
        "interview_consonants_control = interview_consonants[interview_consonants[\"Group\"] == \"Control\"]\n",
        "interview_consonants_control.index = range(len(interview_consonants_control.index))"
      ],
      "metadata": {
        "id": "9keKzOl5s94W"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get means for fluent and disfluent utterances for each group for interview**"
      ],
      "metadata": {
        "id": "xRjsYXfSvlBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# interview, pws\n",
        "fluent_v_i_p = interview_vowels_pws.groupby([\"FluencyStatus\"]).mean()[\"Syllables\"][1]\n",
        "disfluent_v_i_p = interview_vowels_pws.groupby([\"FluencyStatus\"]).mean()[\"Syllables\"][0]\n",
        "fluent_c_i_p = interview_consonants_pws.groupby([\"FluencyStatus\"]).mean()[\"Consonants\"][1]\n",
        "disfluent_c_i_p = interview_consonants_pws.groupby([\"FluencyStatus\"]).mean()[\"Consonants\"][0]"
      ],
      "metadata": {
        "id": "Q0XH2PgOu3KF"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interview, control\n",
        "fluent_v_i_c = interview_vowels_control.groupby([\"FluencyStatus\"]).mean()[\"Syllables\"][1]\n",
        "disfluent_v_i_c = interview_vowels_control.groupby([\"FluencyStatus\"]).mean()[\"Syllables\"][0]\n",
        "fluent_c_i_c = interview_consonants_control.groupby([\"FluencyStatus\"]).mean()[\"Consonants\"][1]\n",
        "disfluent_c_i_c = interview_consonants_control.groupby([\"FluencyStatus\"]).mean()[\"Consonants\"][0]"
      ],
      "metadata": {
        "id": "5WoOxj41vERr"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the Means**"
      ],
      "metadata": {
        "id": "Ntgyw37mxoBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = f\"In the reading condition, disfluent utterances produced by PWS contained {round(disfluent_v_r_p,2)} vowels and {round(disfluent_c_r_p,2)} consonants, while fluent utterances contained {round(fluent_v_r_p,2)} vowels and {round(fluent_c_r_p,2)} consonants.\"\n",
        "string1 = f\"The difference between vowels is {round(fluent_v_r_p - disfluent_v_r_p,2)} and the difference between consonants is {round(fluent_c_r_p - disfluent_c_r_p,2)}. \"\n",
        "string2 = f\"\\nBy contrast, disfluent utterances produced by control participants contained {round(disfluent_v_r_c,2)} vowels and {round(disfluent_c_r_c,2)} consonants, while fluent utterances contained {round(fluent_v_r_c,2)} vowels and {round(fluent_c_r_c,2)} consonants.\"\n",
        "string3 = f\"The difference between vowels is {round(fluent_v_r_c - disfluent_v_r_c,2)} and the difference between consonants is {round(fluent_c_r_c - disfluent_c_r_c,2)}. \""
      ],
      "metadata": {
        "id": "xrDg2_f_zV16"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(string)\n",
        "print(string1)\n",
        "print(string2)\n",
        "print(string3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hECO673Uzir2",
        "outputId": "2d3bf8ff-5c75-4d9e-c253-8fe9ec0c61e4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the reading condition, disfluent utterances produced by PWS contained 8.37 vowels and 13.24 consonants, while fluent utterances contained 11.89 vowels and 18.45 consonants.\n",
            "The difference between vowels is 3.51 and the difference between consonants is 5.21. \n",
            "\n",
            "By contrast, disfluent utterances produced by control participants contained 9.99 vowels and 18.1 consonants, while fluent utterances contained 14.09 vowels and 21.4 consonants.\n",
            "The difference between vowels is 4.11 and the difference between consonants is 3.3. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string = f\"In the interview condition, disfluent utterances produced by PWS contained {round(disfluent_v_i_p,2)} vowels and {round(disfluent_c_i_p,2)} consonants, while fluent utterances contained {round(fluent_v_i_p,2)} vowels and {round(fluent_c_i_p,2)} consonants.\"\n",
        "string1 = f\"The difference between vowels is {round(fluent_v_i_p - disfluent_v_i_p,2)} and the difference between consonants is {round(fluent_c_i_p - disfluent_c_i_p,2)}. \"\n",
        "string2 = f\"\\nBy contrast, disfluent utterances produced by control participants contained {round(disfluent_v_i_c,2)} vowels and {round(disfluent_c_i_c,2)} consonants, while fluent utterances contained {round(fluent_v_i_c,2)} vowels and {round(fluent_c_i_c,2)} consonants.\"\n",
        "string3 = f\"The difference between vowels is {round(fluent_v_i_c - disfluent_v_i_c,2)} and the difference between consonants is {round(fluent_c_i_c - disfluent_c_i_c,2)}. \""
      ],
      "metadata": {
        "id": "jibk29w2qJ5V"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(string)\n",
        "print(string1)\n",
        "print(string2)\n",
        "print(string3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts-p9QZXqJxT",
        "outputId": "bacbacef-28d4-4957-af75-c84d63b3910a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the interview condition, disfluent utterances produced by PWS contained 7.84 vowels and 11.57 consonants, while fluent utterances contained 11.49 vowels and 17.17 consonants.\n",
            "The difference between vowels is 3.64 and the difference between consonants is 5.59. \n",
            "\n",
            "By contrast, disfluent utterances produced by control participants contained 9.87 vowels and 15.33 consonants, while fluent utterances contained 12.14 vowels and 18.99 consonants.\n",
            "The difference between vowels is 2.27 and the difference between consonants is 3.66. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Match fluent vowels and consonants to match the length of disfluent vowels and consonants**"
      ],
      "metadata": {
        "id": "0Zg6i8Uz0uHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading**"
      ],
      "metadata": {
        "id": "TVRczfY14cBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vowels"
      ],
      "metadata": {
        "id": "cBmrpz6m4eKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fluent_vowel_subset = reading_vowels_pws[reading_vowels_pws[\"FluencyStatus\"] == \"Fluent\"]\n",
        "fluent_vowel_subset.index = range(len(fluent_vowel_subset.index))\n",
        "difference_v_read_pws = fluent_v_r_p - disfluent_v_r_p"
      ],
      "metadata": {
        "id": "XmLIy9nR00rc"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cut_v = math.ceil(difference_v_read_pws)                                                         \n",
        "matched_r_v_p = pd.DataFrame()  ## initialize group-level dataframe              \n",
        "participant = pd.DataFrame()  ## initialize participant-level dataframe\n",
        "for ID in IDs:\n",
        "  subset_ID = fluent_vowel_subset[fluent_vowel_subset[\"ID\"]  == ID] \n",
        "  subset_ID.index = range(len(subset_ID.index))  ### person\n",
        "  BGs = subset_ID[\"Breath.Group\"].unique()\n",
        "  for i in range(0,len(BGs)):\n",
        "    subset_ID_BG = subset_ID[subset_ID[\"Breath.Group\"]  == i] \n",
        "    subset_ID_BG.index = range(len(subset_ID_BG.index)) ## BG\n",
        "    if len(subset_ID_BG) >= cut_v:\n",
        "      subset_ID_BG.drop(subset_ID_BG.tail(cut_v).index, inplace = True) \n",
        "      participant = participant.append([subset_ID_BG], ignore_index = True)\n",
        "    else:  \n",
        "      participant = participant.append([subset_ID_BG], ignore_index = True)\n",
        "matched_r_v_p = matched_r_v_p.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe"
      ],
      "metadata": {
        "id": "DQHnlGE000hf"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# consonants "
      ],
      "metadata": {
        "id": "oOTNyTHn27li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fluent_consonant_subset = reading_consonants_pws[reading_consonants_pws[\"FluencyStatus\"] == \"Fluent\"]\n",
        "fluent_consonant_subset.index = range(len(fluent_consonant_subset.index))\n",
        "difference_c_read_pws = fluent_c_r_p - disfluent_c_r_p"
      ],
      "metadata": {
        "id": "7Lfe-KFY38yX"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cut_v = math.ceil(difference_c_read_pws)                                                         \n",
        "matched_r_c_p = pd.DataFrame()  ## initialize group-level dataframe              \n",
        "participant = pd.DataFrame()  ## initialize participant-level dataframe\n",
        "for ID in IDs:\n",
        "  subset_ID = fluent_consonant_subset[fluent_consonant_subset[\"ID\"]  == ID] \n",
        "  subset_ID.index = range(len(subset_ID.index))  ### person\n",
        "  BGs = subset_ID[\"Breath.Group\"].unique()\n",
        "  for i in range(0,len(BGs)):\n",
        "    subset_ID_BG = subset_ID[subset_ID[\"Breath.Group\"]  == i] \n",
        "    subset_ID_BG.index = range(len(subset_ID_BG.index)) ## BG\n",
        "    if len(subset_ID_BG) >= cut_v:\n",
        "      subset_ID_BG.drop(subset_ID_BG.tail(cut_v).index, inplace = True) \n",
        "      participant = participant.append([subset_ID_BG], ignore_index = True)\n",
        "    else:  \n",
        "      participant = participant.append([subset_ID_BG], ignore_index = True)\n",
        "matched_r_c_p = matched_r_c_p.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe"
      ],
      "metadata": {
        "id": "Hbz56MgL38oL"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matched_r_c_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "SbDytUCT4U1g",
        "outputId": "b0d7fc2f-e812-47c1-d4ef-1f13701dee6d"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Group    ID       Type Sound   Onset  Offset  Duration  Breath.Group  \\\n",
              "0      PWS  24fa  consonant   \"S\"   0.143   0.263     0.120             1   \n",
              "1      PWS  24fa  consonant  \"HH\"   0.343   0.482     0.139             1   \n",
              "2      PWS  24fa  consonant   \"R\"   0.573   0.702     0.129             1   \n",
              "3      PWS  24fa  consonant  \"HH\"   3.303   3.403     0.100             3   \n",
              "4      PWS  24fa  consonant   \"V\"   3.433   3.542     0.109             3   \n",
              "...    ...   ...        ...   ...     ...     ...       ...           ...   \n",
              "1955   PWS   62m  consonant   \"R\"  29.595  29.715     0.120            18   \n",
              "1956   PWS   62m  consonant   \"K\"  29.835  29.865     0.030            18   \n",
              "1957   PWS   62m  consonant   \"L\"  29.865  29.896     0.031            18   \n",
              "1958   PWS   62m  consonant   \"T\"  29.946  30.035     0.089            18   \n",
              "1959   PWS   62m  consonant  \"DH\"  30.095  30.136     0.041            18   \n",
              "\n",
              "     FluencyStatus   m  Consonants  \n",
              "0           Fluent  17           9  \n",
              "1           Fluent  17           9  \n",
              "2           Fluent  17           9  \n",
              "3           Fluent  24          14  \n",
              "4           Fluent  24          14  \n",
              "...            ...  ..         ...  \n",
              "1955        Fluent  21          12  \n",
              "1956        Fluent  21          12  \n",
              "1957        Fluent  21          12  \n",
              "1958        Fluent  21          12  \n",
              "1959        Fluent  21          12  \n",
              "\n",
              "[1960 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58d7a301-2a16-422b-b7b7-e18b3e3b325b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Group</th>\n",
              "      <th>ID</th>\n",
              "      <th>Type</th>\n",
              "      <th>Sound</th>\n",
              "      <th>Onset</th>\n",
              "      <th>Offset</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Breath.Group</th>\n",
              "      <th>FluencyStatus</th>\n",
              "      <th>m</th>\n",
              "      <th>Consonants</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PWS</td>\n",
              "      <td>24fa</td>\n",
              "      <td>consonant</td>\n",
              "      <td>\"S\"</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.263</td>\n",
              "      <td>0.120</td>\n",
              "      <td>1</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PWS</td>\n",
              "      <td>24fa</td>\n",
              "      <td>consonant</td>\n",
              "      <td>\"HH\"</td>\n",
              "      <td>0.343</td>\n",
              "      <td>0.482</td>\n",
              "      <td>0.139</td>\n",
              "      <td>1</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PWS</td>\n",
              "      <td>24fa</td>\n",
              "      <td>consonant</td>\n",
              "      <td>\"R\"</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0.702</td>\n",
              "      <td>0.129</td>\n",
              "      <td>1</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PWS</td>\n",
              "      <td>24fa</td>\n",
              "      <td>consonant</td>\n",
              "      <td>\"HH\"</td>\n",
              "      <td>3.303</td>\n",
              "      <td>3.403</td>\n",
              "      <td>0.100</td>\n",
              "      <td>3</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PWS</td>\n",
              "      <td>24fa</td>\n",
              "      <td>consonant</td>\n",
              "      <td>\"V\"</td>\n",
              "      <td>3.433</td>\n",
              "      <td>3.542</td>\n",
              "      <td>0.109</td>\n",
              "      <td>3</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1955</th>\n",
              "      <td>PWS</td>\n",
              "      <td>62m</td>\n",
              "      <td>consonant</td>\n",
              "      <td>\"R\"</td>\n",
              "      <td>29.595</td>\n",
              "      <td>29.715</td>\n",
              "      <td>0.120</td>\n",
              "      <td>18</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1956</th>\n",
              "      <td>PWS</td>\n",
              "      <td>62m</td>\n",
              "      <td>consonant</td>\n",
              "      <td>\"K\"</td>\n",
              "      <td>29.835</td>\n",
              "      <td>29.865</td>\n",
              "      <td>0.030</td>\n",
              "      <td>18</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1957</th>\n",
              "      <td>PWS</td>\n",
              "      <td>62m</td>\n",
              "      <td>consonant</td>\n",
              "      <td>\"L\"</td>\n",
              "      <td>29.865</td>\n",
              "      <td>29.896</td>\n",
              "      <td>0.031</td>\n",
              "      <td>18</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1958</th>\n",
              "      <td>PWS</td>\n",
              "      <td>62m</td>\n",
              "      <td>consonant</td>\n",
              "      <td>\"T\"</td>\n",
              "      <td>29.946</td>\n",
              "      <td>30.035</td>\n",
              "      <td>0.089</td>\n",
              "      <td>18</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1959</th>\n",
              "      <td>PWS</td>\n",
              "      <td>62m</td>\n",
              "      <td>consonant</td>\n",
              "      <td>\"DH\"</td>\n",
              "      <td>30.095</td>\n",
              "      <td>30.136</td>\n",
              "      <td>0.041</td>\n",
              "      <td>18</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1960 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58d7a301-2a16-422b-b7b7-e18b3e3b325b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58d7a301-2a16-422b-b7b7-e18b3e3b325b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58d7a301-2a16-422b-b7b7-e18b3e3b325b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interview**"
      ],
      "metadata": {
        "id": "d2IwqS4Y4qID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vowels"
      ],
      "metadata": {
        "id": "mJyVgH7R4src"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fluent_vowel_subset = interview_vowels_pws[interview_vowels_pws[\"FluencyStatus\"] == \"Fluent\"]\n",
        "fluent_vowel_subset.index = range(len(fluent_vowel_subset.index))\n",
        "difference_v_inter_pws = fluent_v_i_p - disfluent_v_i_p"
      ],
      "metadata": {
        "id": "Jep072T34sn7"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cut_v = math.ceil(difference_v_inter_pws)                                                         \n",
        "matched_i_v_p = pd.DataFrame()  ## initialize group-level dataframe              \n",
        "participant = pd.DataFrame()  ## initialize participant-level dataframe\n",
        "for ID in IDs:\n",
        "  subset_ID = fluent_vowel_subset[fluent_vowel_subset[\"ID\"]  == ID] \n",
        "  subset_ID.index = range(len(subset_ID.index))  ### person\n",
        "  BGs = subset_ID[\"Breath.Group\"].unique()\n",
        "  for i in range(0,len(BGs)):\n",
        "    subset_ID_BG = subset_ID[subset_ID[\"Breath.Group\"]  == i] \n",
        "    subset_ID_BG.index = range(len(subset_ID_BG.index)) ## BG\n",
        "    if len(subset_ID_BG) >= cut_v:\n",
        "      subset_ID_BG.drop(subset_ID_BG.tail(cut_v).index, inplace = True) \n",
        "      participant = participant.append([subset_ID_BG], ignore_index = True)\n",
        "    else:  \n",
        "      participant = participant.append([subset_ID_BG], ignore_index = True)\n",
        "matched_i_v_p = matched_i_v_p.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe"
      ],
      "metadata": {
        "id": "3r-K0Asp4slf"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# consonants"
      ],
      "metadata": {
        "id": "TM9Ll-t54si_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fluent_consonant_subset = interview_consonants_pws[interview_consonants_pws[\"FluencyStatus\"] == \"Fluent\"]\n",
        "fluent_consonant_subset.index = range(len(fluent_consonant_subset.index))\n",
        "difference_c_inter_pws = fluent_c_i_p - disfluent_c_i_p"
      ],
      "metadata": {
        "id": "AGJSVSW55KBC"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cut_v = math.ceil(difference_c_inter_pws)                                                         \n",
        "matched_i_c_p = pd.DataFrame()  ## initialize group-level dataframe              \n",
        "participant = pd.DataFrame()  ## initialize participant-level dataframe\n",
        "for ID in IDs:\n",
        "  subset_ID = fluent_consonant_subset[fluent_consonant_subset[\"ID\"]  == ID] \n",
        "  subset_ID.index = range(len(subset_ID.index))  ### person\n",
        "  BGs = subset_ID[\"Breath.Group\"].unique()\n",
        "  for i in range(0,len(BGs)):\n",
        "    subset_ID_BG = subset_ID[subset_ID[\"Breath.Group\"]  == i] \n",
        "    subset_ID_BG.index = range(len(subset_ID_BG.index)) ## BG\n",
        "    if len(subset_ID_BG) >= cut_v:\n",
        "      subset_ID_BG.drop(subset_ID_BG.tail(cut_v).index, inplace = True) \n",
        "      participant = participant.append([subset_ID_BG], ignore_index = True)\n",
        "    else:  \n",
        "      participant = participant.append([subset_ID_BG], ignore_index = True)\n",
        "matched_i_c_p = matched_i_c_p.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe"
      ],
      "metadata": {
        "id": "JSCj1du95JwF"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count new number of Sounds in BG: Reading**"
      ],
      "metadata": {
        "id": "_Z9apnEE8pKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = -1\n",
        "avg_col = pd.DataFrame(index = range(len(subj_col[0:18])),columns=[\"Syllables\"])\n",
        "for ID in IDs: ## loop over participnts\n",
        "  n = n + 1\n",
        "  subset_BGs = matched_r_v_p[matched_r_v_p[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "  subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "  BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "  subj_avg = BG_avg[\"Syllables\"].mean()\n",
        "  avg_col[\"Syllables\"][n] = subj_avg\n",
        "participant_vowel_r_p_avg = pd.concat([subj_col[0:18], avg_col], axis=1)"
      ],
      "metadata": {
        "id": "u-votYFe8s1a"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = -1\n",
        "avg_col_c = pd.DataFrame(index = range(len(subj_col[0:18])),columns=[\"Consonants\"])\n",
        "for ID in IDs: ## loop over participnts\n",
        "  n = n + 1\n",
        "  subset_BGs = matched_r_c_p[matched_r_c_p[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "  subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "  BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "  subj_avg_c = BG_avg[\"Consonants\"].mean()\n",
        "  avg_col_c[\"Consonants\"][n] = subj_avg_c\n",
        "participant_consonant_r_p_avg = pd.concat([subj_col[0:18], avg_col_c], axis=1)"
      ],
      "metadata": {
        "id": "o9rzKx6J-CZP"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the new means**"
      ],
      "metadata": {
        "id": "JhHbwLfQ5lLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading"
      ],
      "metadata": {
        "id": "aZxZ4GfP_Pri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_vowel = participant_vowel_r_p_avg[\"Syllables\"].mean()"
      ],
      "metadata": {
        "id": "vNMAhbru7f9R"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_cons = participant_consonant_r_p_avg[\"Consonants\"].mean()"
      ],
      "metadata": {
        "id": "jxhouGxf6kJR"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string = f\"In the reading condition, disfluent utterances produced by PWS contained {round(disfluent_v_r_p,2)} vowels and {round(disfluent_c_r_p,2)} consonants, while fluent utterances contained {round(new_vowel,2)} vowels and {round(new_cons,2)} consonants.\"\n",
        "string1 = f\"The difference between vowels is {round(fluent_v_r_p - disfluent_v_r_p,2)} and the difference between consonants is {round(fluent_c_r_p - disfluent_c_r_p,2)}. \""
      ],
      "metadata": {
        "id": "h0p7-j4e5n2t"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxJNaUZK7N90",
        "outputId": "bdceef8f-d785-4e9b-a0bc-f3700e7e176c"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the reading condition, disfluent utterances produced by PWS contained 8.37 vowels and 13.24 consonants, while fluent utterances contained 9.41 vowels and 13.88 consonants.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count new number of Sounds in BG: Interview**"
      ],
      "metadata": {
        "id": "xBICT5WPAjGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# interview\n",
        "n = -1\n",
        "avg_col = pd.DataFrame(index = range(len(subj_col[0:18])),columns=[\"Syllables\"])\n",
        "for ID in IDs: ## loop over participnts\n",
        "  n = n + 1\n",
        "  subset_BGs = matched_i_v_p[matched_i_v_p[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "  subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "  BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "  subj_avg = BG_avg[\"Syllables\"].mean()\n",
        "  avg_col[\"Syllables\"][n] = subj_avg\n",
        "participant_vowel_i_p_avg = pd.concat([subj_col[0:18], avg_col], axis=1)"
      ],
      "metadata": {
        "id": "VEIO-Wh0_w70"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = -1\n",
        "avg_col_c = pd.DataFrame(index = range(len(subj_col[0:18])),columns=[\"Consonants\"])\n",
        "for ID in IDs: ## loop over participnts\n",
        "  n = n + 1\n",
        "  subset_BGs = matched_i_c_p[matched_i_c_p[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "  subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "  BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "  subj_avg_c = BG_avg[\"Consonants\"].mean()\n",
        "  avg_col_c[\"Consonants\"][n] = subj_avg_c\n",
        "participant_consonant_i_p_avg = pd.concat([subj_col[0:18], avg_col_c], axis=1)"
      ],
      "metadata": {
        "id": "-GJ-L16G_9rc"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the new means**"
      ],
      "metadata": {
        "id": "03tASCSYAo4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_vowel = participant_vowel_i_p_avg[\"Syllables\"].mean()\n",
        "new_cons = participant_consonant_i_p_avg[\"Consonants\"].mean()"
      ],
      "metadata": {
        "id": "g-HM-oYEALCW"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string = f\"In the interview condition, disfluent utterances produced by PWS contained {round(disfluent_v_i_p,2)} vowels and {round(disfluent_c_i_p,2)} consonants, while fluent utterances contained {round(new_vowel,2)} vowels and {round(new_cons,2)} consonants.\"\n",
        "string1 = f\"The difference between vowels is {round(fluent_v_r_p - disfluent_v_r_p,2)} and the difference between consonants is {round(fluent_c_r_p - disfluent_c_r_p,2)}. \""
      ],
      "metadata": {
        "id": "kcUNcc4YAPn6"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8efv4vrcAXtV",
        "outputId": "bd12db84-57ba-4cd4-fd8b-30a4550fd96c"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the interview condition, disfluent utterances produced by PWS contained 7.84 vowels and 11.57 consonants, while fluent utterances contained 8.92 vowels and 12.91 consonants.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Export FluencyStatus Results**"
      ],
      "metadata": {
        "id": "Wng4SmfyA5TI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Create output dataframes**"
      ],
      "metadata": {
        "id": "WjmI0TvaDBAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reading_vowels_pws_disfluent = reading_vowels_pws[reading_vowels_pws[\"FluencyStatus\"] == \"Disfluent\"]\n",
        "matched_r_v_p = matched_r_v_p.append(reading_vowels_pws_disfluent)\n",
        "matched_r_v_p.index = range(len(matched_r_v_p.index)) "
      ],
      "metadata": {
        "id": "NNoIxY8ABYp6"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reading_consonants_pws_disfluent = reading_consonants_pws[reading_consonants_pws[\"FluencyStatus\"] == \"Disfluent\"]\n",
        "matched_r_c_p = matched_r_c_p.append(reading_consonants_pws_disfluent)\n",
        "matched_r_c_p.index = range(len(matched_r_c_p.index)) "
      ],
      "metadata": {
        "id": "eD4bT-fBCby8"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interview_vowels_pws_disfluent = interview_vowels_pws[interview_vowels_pws[\"FluencyStatus\"] == \"Disfluent\"]\n",
        "matched_i_v_p = matched_i_v_p.append(interview_vowels_pws_disfluent)\n",
        "matched_i_v_p.index = range(len(matched_i_v_p.index)) "
      ],
      "metadata": {
        "id": "8eqEixo4Cooq"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interview_consonants_pws_disfluent = interview_consonants_pws[interview_consonants_pws[\"FluencyStatus\"] == \"Disfluent\"]\n",
        "matched_i_c_p = matched_i_c_p.append(interview_consonants_pws_disfluent)\n",
        "matched_i_c_p.index = range(len(matched_i_c_p.index)) "
      ],
      "metadata": {
        "id": "FwtPVz-3C0u4"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Change Directory and Save**"
      ],
      "metadata": {
        "id": "GSPy_B9-DGMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline/3.MLU_Matched/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJN9x178BAlo",
        "outputId": "bf7bc1a0-e350-45d3-971a-55d7bd809284"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/RhythmAnalysisPipeline/3.MLU_Matched\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matched_r_v_p.to_excel(\"matchedVowels_reading.xlsx\")\n",
        "matched_r_c_p.to_excel(\"matchedConsonants_reading.xlsx\")\n",
        "matched_i_v_p.to_excel(\"matchedVowels_interview.xlsx\")\n",
        "matched_i_c_p.to_excel(\"matchedConsonants_interview.xlsx\")"
      ],
      "metadata": {
        "id": "gQqPBpqcBBNn"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline/"
      ],
      "metadata": {
        "id": "xH0sPBg-Emh0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}